# Oil Spill Detection System Design

## é¡¹ç›®æ¦‚è¿°

å†¬å­£é«˜ç©ºæ— äººæœºè§†è§’ä¸‹çŸ³æ²¹æ³„æ¼ç›‘æµ‹ç³»ç»Ÿï¼Œé‡‡ç”¨ç«¯äº‘ååŒçš„ä¸¤é˜¶æ®µæ¶æ„ï¼š
- **Stage 1**: ä¼ ç»Ÿ CV å¿«é€Ÿç²—ç­›ï¼ˆOpenCVï¼‰
- **Stage 2**: VLM è¯­ä¹‰éªŒè¯ï¼ˆGPT-4o / LLaVAï¼‰

---

## ç³»ç»Ÿæ¶æ„

### ç±»ç»“æ„å›¾

```mermaid
classDiagram
    class OilSpillDetector {
        -ir_threshold: int
        -rgb_dark_threshold: int
        -min_area: int
        -max_area: int
        -vlm_api_key: str
        -vlm_model: str
        -clahe_clip_limit: float
        -morph_kernel_size: int
        -min_crop_size: int
        -padding_size: int
        +__init__(config)
        +preprocess_images(ir_frame, rgb_frame) tuple
        +generate_proposals(ir_frame, rgb_frame) list
        +verify_with_vlm(crop_ir, crop_rgb) dict
        +_enhance_small_crop(crop_ir, crop_rgb) tuple
        +_filter_regular_shapes(contour, bbox) bool
        +detect(ir_frame, rgb_frame) list
        +visualize_results(rgb_frame, proposals, verified) None
    }
    
    class Proposal {
        +bbox: tuple
        +area: float
        +ir_temp: float
        +rgb_color: tuple
        +contour: np.ndarray
    }
    
    class VLMResult {
        +is_leak: bool
        +confidence: str
        +reason: str
    }
    
    OilSpillDetector --> Proposal
    OilSpillDetector --> VLMResult
```

### å·¥ä½œæµç¨‹å›¾

```mermaid
flowchart TD
    A[è¾“å…¥ RGBT è§†é¢‘æµ] --> B[preprocess_images]
    B --> C[generate_proposals - Stage 1]
    
    subgraph Stage1 [Stage 1: ä¼ ç»ŸCVç²—ç­›]
        C --> C1[çº¢å¤–é˜ˆå€¼æå–çƒ­ç‚¹]
        C1 --> C2[RGBé¢œè‰²è¿‡æ»¤]
        C2 --> C3[å½¢çŠ¶è§„åˆ™æ€§è¿‡æ»¤]
        C3 --> C4[è¾“å‡ºå€™é€‰æ¡†åˆ—è¡¨]
    end
    
    C4 --> D{æœ‰å€™é€‰æ¡†?}
    D -->|å¦| E[è¿”å›ç©ºç»“æœ]
    D -->|æ˜¯| F[verify_with_vlm - Stage 2]
    
    subgraph Stage2 [Stage 2: VLMéªŒè¯]
        F --> F1[éå†å€™é€‰æ¡†]
        F1 --> F2{ç›®æ ‡å¤ªå°?}
        F2 -->|æ˜¯| F3[Padding/æ”¾å¤§]
        F2 -->|å¦| F4[ç›´æ¥è£å‰ª]
        F3 --> F5[è°ƒç”¨VLM API]
        F4 --> F5
        F5 --> F6[è§£æç»“æœ]
        F6 --> F7{è¿˜æœ‰å€™é€‰?}
        F7 -->|æ˜¯| F1
        F7 -->|å¦| F8[è¾“å‡ºç¡®è®¤æ¡†]
    end
    
    F8 --> G[visualize_results]
    G --> H[ç»˜åˆ¶æœ€ç»ˆç»“æœ]
```

---

## å®Œæ•´ä»£ç æ¡†æ¶

### æ–‡ä»¶: `src/oil_spill_detector.py`

```python
import cv2
import numpy as np
import base64
import json
from typing import List, Tuple, Optional
from dataclasses import dataclass


@dataclass
class Proposal:
    bbox: Tuple[int, int, int, int]
    area: float
    ir_temp: float
    rgb_color: Tuple[int, int, int]
    contour: np.ndarray


@dataclass
class VLMResult:
    is_leak: bool
    confidence: str
    reason: str


class OilSpillDetector:
    def __init__(
        self,
        ir_threshold: int = 200,
        rgb_dark_threshold: int = 80,
        min_area: int = 500,
        max_area: int = 100000,
        vlm_api_key: Optional[str] = None,
        vlm_model: str = "gpt-4o",
        clahe_clip_limit: float = 3.0,
        clahe_grid_size: Tuple[int, int] = (8, 8),
        gaussian_blur_kernel: int = 5,
        morph_kernel_size: int = 20,
        min_crop_size: int = 64,
        padding_size: int = 10,
    ):
        self.ir_threshold = ir_threshold
        self.rgb_dark_threshold = rgb_dark_threshold
        self.min_area = min_area
        self.max_area = max_area
        self.vlm_api_key = vlm_api_key
        self.vlm_model = vlm_model
        self.clahe_clip_limit = clahe_clip_limit
        self.clahe_grid_size = clahe_grid_size
        self.gaussian_blur_kernel = gaussian_blur_kernel
        self.morph_kernel_size = morph_kernel_size
        self.min_crop_size = min_crop_size
        self.padding_size = padding_size
        
        self.clahe = cv2.createCLAHE(clipLimit=self.clahe_clip_limit, tileGridSize=self.clahe_grid_size)
        self.morph_kernel = np.ones((self.morph_kernel_size, self.morph_kernel_size), np.uint8)
    
    def preprocess_images(self, ir_frame: np.ndarray, rgb_frame: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        if len(ir_frame.shape) == 3:
            ir_frame = cv2.cvtColor(ir_frame, cv2.COLOR_BGR2GRAY)
        ir_frame = cv2.normalize(ir_frame, None, 0, 255, cv2.NORM_MINMAX)
        
        if len(rgb_frame.shape) == 2:
            rgb_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_GRAY2BGR)
        
        if ir_frame.shape != rgb_frame.shape[:2]:
            rgb_frame = cv2.resize(rgb_frame, (ir_frame.shape[1], ir_frame.shape[0]))
        
        return ir_frame, rgb_frame
    
    def _filter_regular_shapes(self, contour: np.ndarray, bbox: Tuple[int, int, int, int]) -> bool:
        x, y, w, h = bbox
        contour_area = cv2.contourArea(contour)
        bbox_area = w * h
        
        if bbox_area == 0:
            return False
        
        solidity = contour_area / bbox_area
        if solidity > 0.85:
            return False
        
        aspect_ratio = float(w) / h if h > 0 else 0
        if aspect_ratio > 5.0 or aspect_ratio < 0.2:
            return False
        
        hull = cv2.convexHull(contour)
        hull_area = cv2.contourArea(hull)
        
        if hull_area == 0:
            return False
        
        convexity = contour_area / hull_area
        if convexity > 0.95:
            return False
        
        moments = cv2.moments(contour)
        if moments['m00'] == 0:
            return False
        
        perimeter = cv2.arcLength(contour, True)
        if perimeter == 0:
            return False
        
        circularity = 4 * np.pi * contour_area / (perimeter ** 2)
        if circularity > 0.85:
            return False
        

        
        return True
    
    def generate_proposals(self, ir_frame: np.ndarray, rgb_frame: np.ndarray) -> List[Proposal]:
        print(f"ğŸš€ [Stage 1] Generating proposals...")
        
        ir_enhanced = self.clahe.apply(ir_frame)
        ir_blur = cv2.GaussianBlur(ir_enhanced, (self.gaussian_blur_kernel, self.gaussian_blur_kernel), 0)
        _, ir_mask = cv2.threshold(ir_blur, self.ir_threshold, 255, cv2.THRESH_BINARY)
        
        rgb_gray = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2GRAY)
        _, rgb_mask = cv2.threshold(rgb_gray, self.rgb_dark_threshold, 255, cv2.THRESH_BINARY_INV)
        
        final_mask = cv2.bitwise_and(ir_mask, rgb_mask)
        final_mask = cv2.morphologyEx(final_mask, cv2.MORPH_DILATE, self.morph_kernel)
        
        contours, _ = cv2.findContours(final_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        proposals = []
        for contour in contours:
x, y, w, h = cv2.boundingRect(contour)
            bbox = (x, y, w, h)
            
            area = cv2.contourArea(contour)
            if area < self.min_area or area > self.max_area:
                continue
            
            if not self._filter_regular_shapes(contour, bbox):
                continue
            
            ir_roi = ir_frame[y:y+h, x:x+w]
            ir_temp = float(np.mean(ir_roi)) if ir_roi.size > 0 else 0.0
            
            rgb_roi = rgb_frame[y:y+h, x:x+w]
            rgb_color = tuple(map(int, np.mean(rgb_roi, axis=(0, 1)))) if rgb_roi.size > 0 else (0, 0, 0)
            
            proposals.append(Proposal(bbox=bbox, area=area, ir_temp=ir_temp, rgb_color=rgb_color, contour=contour))
        
        print(f"âœ… [Stage 1] Generated {len(proposals)} proposals")
        return proposals
    
    def _enhance_small_crop(self, crop_ir: np.ndarray, crop_rgb: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        h_ir, w_ir = crop_ir.shape[:2]
        
        if h_ir < self.min_crop_size or w_ir < self.min_crop_size:
            scale = max(self.min_crop_size / h_ir, self.min_crop_size / w_ir)
            new_h_ir = int(h_ir * scale)
            new_w_ir = int(w_ir * scale)
            crop_ir = cv2.resize(crop_ir, (new_w_ir, new_h_ir), interpolation=cv2.INTER_CUBIC)
            
            h_rgb, w_rgb = crop_rgb.shape[:2]
            new_h_rgb = int(h_rgb * scale)
            new_w_rgb = int(w_rgb * scale)
            crop_rgb = cv2.resize(crop_rgb, (new_w_rgb, new_h_rgb), interpolation=cv2.INTER_CUBIC)
            
            print(f"ğŸ” [Active Observation] Resized crop from ({w_ir}x{h_ir}) to ({new_w_ir}x{new_h_ir})")
        
        return crop_ir, crop_rgb
    
    def _encode_image_to_base64(self, image: np.ndarray) -> str:
        _, buffer = cv2.imencode('.jpg', image)
        return f"data:image/jpeg;base64,{base64.b64encode(buffer).decode('utf-8')}"
    
    def verify_with_vlm(self, crop_ir: np.ndarray, crop_rgb: np.ndarray) -> VLMResult:
        crop_ir, crop_rgb = self._enhance_small_crop(crop_ir, crop_rgb)
        
        if len(crop_ir.shape) == 2:
            crop_ir = cv2.cvtColor(crop_ir, cv2.COLOR_GRAY2BGR)
        
        combined_img = np.hstack((crop_ir, crop_rgb))
        base64_img = self._encode_image_to_base64(combined_img)
        
        # System Prompt for VLM - KEY to distinguishing soil, machinery, and oil spills
        system_prompt = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ²¹ç”°å·¥ä¸šè§†è§‰ä¸“å®¶ï¼Œæ“…é•¿ä»é«˜ç©ºæ— äººæœºè§†è§’è¯†åˆ«å†¬å­£ç¯å¢ƒä¸‹çš„çŸ³æ²¹æ³„æ¼ã€‚

ã€å›¾åƒè¯´æ˜ã€‘
- å·¦ä¾§å›¾åƒï¼šçº¢å¤–çƒ­æˆåƒï¼ˆé«˜äº®åŒºåŸŸä»£è¡¨é«˜æ¸©ï¼Œæš—è‰²åŒºåŸŸä»£è¡¨ä½æ¸©ï¼‰
- å³ä¾§å›¾åƒï¼šå¯è§å…‰RGBå›¾åƒ

ã€ä»»åŠ¡ã€‘
è¯·åˆ¤æ–­å›¾åƒä¸­æ˜¯å¦åŒ…å«ã€åœ°é¢çŸ³æ²¹æ³„æ¼ã€‘ã€‚

ã€åˆ¤æ–­æ ‡å‡†ã€‘

1. çŸ³æ²¹æ³„æ¼ç‰¹å¾ï¼š
   - çº¢å¤–ç‰¹å¾ï¼šä¸­å¿ƒé«˜æ¸©ï¼Œè¾¹ç¼˜ä½æ¸©ï¼Œå‘ˆæ”¾å°„çŠ¶æ¢¯åº¦åˆ†å¸ƒ
   - RGBç‰¹å¾ï¼šé»‘è‰²æˆ–æ·±è¤è‰²ï¼Œå½¢çŠ¶ä¸è§„åˆ™ï¼ˆéå‡ ä½•å½¢çŠ¶ï¼‰
   - è¾¹ç¼˜ç‰¹å¾ï¼šè¾¹ç¼˜å‘ˆé”¯é½¿çŠ¶ã€ç¾½åŒ–çŠ¶æˆ–æ¸—é€çŠ¶
   - æ‰©æ•£ç‰¹å¾ï¼šçœ‹èµ·æ¥åƒæ¶²ä½“åœ¨åœ°é¢æ¸—é€æˆ–æ‰©æ•£
   - æ¸©åº¦ç‰¹å¾ï¼šçº¢å¤–æœ‰æ˜æ˜¾çš„æ¸©å·®åˆ†å¸ƒ

2. å¹²æ‰°ç‰©ç‰¹å¾ï¼š
   - è£¸éœ²åœŸå£¤ï¼šæ£•è¤è‰²ï¼Œè¾¹ç¼˜é”åˆ©ï¼Œæ¸©åº¦åˆ†å¸ƒå‡åŒ€ï¼Œæ— æ”¾å°„çŠ¶æ¢¯åº¦
   - ç®¡é“/è®¾å¤‡ï¼šç¬”ç›´çº¿æ¡ï¼Œè§„åˆ™å‡ ä½•å½¢çŠ¶ï¼Œè¾¹ç¼˜é”åˆ©
   - è½¦è¾†/æœºæ¢°ï¼šå­¤ç«‹å›ºä½“å½¢æ€ï¼Œæœ‰æ˜æ˜¾çš„è½®å»“å’Œç»“æ„
   - é˜´å½±ï¼šé»‘è‰²/æ·±ç°è‰²ï¼Œè¾¹ç¼˜é”åˆ©ï¼Œå‡ ä½•å½¢çŠ¶è§„åˆ™

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ä»…è¾“å‡ºJSONæ ¼å¼ï¼š
{"is_leak": true/false, "confidence": "high/medium/low", "reason": "ç®€è¿°åˆ¤æ–­ä¾æ®"}
"""
        
        # Simulated VLM call (replace with actual API call)
        # For demonstration, return a mock result
        return VLMResult(
            is_leak=False,
            confidence="low",
            reason="Simulated VLM response - replace with actual API call"
        )
    
    def detect(self, ir_frame: np.ndarray, rgb_frame: np.ndarray) -> Tuple[List[Proposal], List[VLMResult]]:
        ir_frame, rgb_frame = self.preprocess_images(ir_frame, rgb_frame)
        proposals = self.generate_proposals(ir_frame, rgb_frame)
        
        verified_results = []
        for proposal in proposals:
            x, y, w, h = proposal.bbox
            
            x1, y1 = max(0, x - self.padding_size), max(0, y - self.padding_size)
            x2, y2 = min(rgb_frame.shape[1], x + w + self.padding_size), min(rgb_frame.shape[0], y + h + self.padding_size)
            
            crop_rgb = rgb_frame[y1:y2, x1:x2]
            crop_ir = ir_frame[y1:y2, x1:x2]
            
            result = self.verify_with_vlm(crop_ir, crop_rgb)
            verified_results.append(result)
        
        return proposals, verified_results
    
    def visualize_results(
        self,
        rgb_frame:: np.ndarray,
        proposals: List[Proposal],
        verified_results: List[VLMResult],
        show: bool = True,
        save_path: Optional[str] = None
    ) -> np.ndarray:
        result_img = rgb_frame.copy()
        
        for proposal, result in zip(proposals, verified_results):
            x, y, w, h = proposal.bbox
            
            if result.is_leak:
                color = (0, 255, 0)  # Green for confirmed leak
                label = f"LEAK ({result.confidence})"
                thickness = 3
            else:
                color = (0, 0, 255)  # Red for proposal (rejected)
                label = "Ignored"
                thickness = 2
            
            cv2.rectangle(result_img, (x, y), (x + w, y + h), color, thickness)
            cv2.putText(result_img, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        if show:
            cv2.imshow("Oil Spill Detection Results", result_img)
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        
        if save_path:
            cv2.imwrite(save_path, result_img)
            print(f"âœ… Result saved to: {save_path}")
        
        return result_img
```

---

## ä½¿ç”¨ç¤ºä¾‹

### æ–‡ä»¶: `examples/run_detector.py`

```python
import cv2
from src.oil_spill_detector import OilSpillDetector

# Initialize detector
detector = OilSpillDetector(
    ir_threshold=200,
    rgb_dark_threshold=80,
    min_area=500,
    max_area=100000,
    vlm_api_key="your-api-key-here",
    vlm_model="gpt-4o",
    min_crop_size=64,
    padding_size=10
)

# Load images
ir_frame = cv2.imread("path/to/ir_image.jpg", cv2.IMREAD_GRAYSCALE)
rgb_frame = cv2.imread("path/to/rgb_image.jpg")

# Detect
proposals, verified_results = detector.detect(ir_frame, rgb_frame)

# Visualize
detector.visualize_results(
    rgb_frame,
    proposals,
    verified_results,
    show=True,
    save_path="results/detection_result.jpg"
)

# Print results
for i, (proposal, result) in enumerate(zip(proposals, verified_results)):
    print(f"Proposal {i+1}: bbox={proposal.bbox}, is_leak={result.is_leak}, reason={result.reason}")
```

---

## å…³é”®æŠ€æœ¯ç‚¹

1. **å¤šå°ºåº¦æ£€æµ‹**: é€šè¿‡ä¸åŒå°ºåº¦æ•è·ä¸åŒå¤§å°çš„ç›®æ ‡
2. **åŒæµèåˆ**: çº¢å¤–çƒ­æˆåƒ + å¯è§å…‰äº’è¡¥ä¿¡æ¯
3. **å½¢æ€å­¦å»å™ª**: 20Ã—20 æ ¸è†¨èƒ€èšåˆç¢ç‰‡åŒºåŸŸ
4. **å½¢çŠ¶è§„åˆ™æ€§è¿‡æ»¤**: è¿‡æ»¤æ‰ç®¡é“ã€è®¾å¤‡ç­‰è§„åˆ™å½¢çŠ¶
5. **ç«¯äº‘ååŒ**: æœ¬åœ°å¿«é€Ÿç­›é€‰ + äº‘ç«¯ç²¾å‡†éªŒè¯
6. **ä¸»åŠ¨è§‚æµ‹**: å°ç›®æ ‡è‡ªåŠ¨æ”¾å¤§ä»¥æé«˜ VLM ç†è§£èƒ½åŠ›

---

## VLM System Prompt è®¾è®¡

System Prompt æ˜¯åŒºåˆ†åœŸå£¤ã€æœºæ¢°å’Œæ²¹æ±¡çš„å…³é”®ï¼š

| ç‰¹å¾ | çŸ³æ²¹æ³„æ¼ | è£¸éœ²åœŸå£¤ | ç®¡é“/è®¾å¤‡ | è½¦è¾†/æœºæ¢° | é˜´å½± |
|------|----------|----------|-----------|-----------|------|
| RGBé¢œè‰² | é»‘è‰²/æ·±è¤è‰² | æ£•è¤è‰² | å„ç§é¢œè‰² | å„ç§é¢œè‰² | é»‘è‰²/æ·±ç° |
| çº¢å¤–ç‰¹å¾ | æ”¾å°„çŠ¶æ¢¯åº¦ | æ¸©åº¦å‡åŒ€ | é«˜æ¸©è§„åˆ™ | é«˜æ¸©è§„åˆ™ | ä½æ¸©å‡åŒ€ |
| è¾¹ç¼˜ç‰¹å¾ | é”¯é½¿/ç¾½åŒ– | é”åˆ© | é”åˆ© | é”åˆ© | é”åˆ© |
| å½¢çŠ¶ | ä¸è§„åˆ™ | è§„åˆ™ | å‡ ä½•è§„åˆ™ | å‡ ä½•è§„åˆ™ | å‡ ä½•è§„åˆ™ |
| æ‰©æ•£æ„Ÿ | æ¶²ä½“æ¸—é€ | æ—  | æ—  | æ—  | æ—  |
